{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMofBrzrj7S3gGRtI/U11U7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantVKathar/Hand_Gesture_volume_controll/blob/main/NLP_PRAC_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Write down python code to find out sentimental polarity +ve -ve neutral of a sentence .**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "vFqsHR4pkqe6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kpX_Mn8fD7s",
        "outputId": "b5e0a42b-0774-4cc8-bfa5-f89c42e88661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install textblob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def get_sentiment_polarity(sentence):\n",
        "    analysis = TextBlob(sentence)\n",
        "    sentiment_polarity = analysis.sentiment.polarity\n",
        "    if sentiment_polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif sentiment_polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# List of sentences\n",
        "sentences = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"The weather is terrible today.\",\n",
        "    \"Neutral sentences are neither positive nor negative.\",\n",
        "    \"my name is vedant\"\n",
        "]\n",
        "\n",
        "# Analyze sentiment for each sentence\n",
        "for sentence in sentences:\n",
        "    sentiment = get_sentiment_polarity(sentence)\n",
        "    print(f\"Sentence: '{sentence}' has a sentiment of {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej9NfkTyfWmM",
        "outputId": "fa652368-7195-485d-9a24-535dbb9102b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I love this product! It's amazing.' has a sentiment of Positive\n",
            "Sentence: 'The weather is terrible today.' has a sentiment of Negative\n",
            "Sentence: 'Neutral sentences are neither positive nor negative.' has a sentiment of Negative\n",
            "Sentence: 'my name is vedant' has a sentiment of Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **- To use different approches similar to following :**\n",
        "\n",
        " - input a sentence  \n",
        "\n",
        " - preprocess\n",
        "\n",
        "- tokenize the sentence\n",
        "\n",
        "- find out the sentiment colarity of an individual word token\n",
        "\n",
        "- sum of all of them to calculate the total colarity"
      ],
      "metadata": {
        "id": "ZyqrogChiiC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu3TbWo-jtpH",
        "outputId": "7d8c7b8f-a4a1-4591-e917-f89ef638c190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to calculate sentiment polarity for a word\n",
        "def get_word_sentiment_polarity(word):\n",
        "    analysis = TextBlob(word)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "# Function to preprocess, tokenize, and calculate total sentence polarity\n",
        "def analyze_sentence_sentiment(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # Calculate the sentiment polarity for each word\n",
        "    word_polarities = [get_word_sentiment_polarity(word) for word in words]\n",
        "\n",
        "    # Calculate the total sentence polarity by summing word polarities\n",
        "    total_polarity = sum(word_polarities)\n",
        "\n",
        "    return total_polarity\n",
        "\n",
        "# List of sentences\n",
        "sentences = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"The weather is terrible today.\",\n",
        "    \"Neutral sentences are neither positive nor negative.\",\n",
        "]\n",
        "\n",
        "# Analyze sentiment for each sentence\n",
        "for sentence in sentences:\n",
        "    total_polarity = analyze_sentence_sentiment(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Total Sentiment Polarity: {total_polarity}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhbIGLtDjvph",
        "outputId": "237de5a2-afd2-4b2c-f874-ca5bee3e5898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I love this product! It's amazing.'\n",
            "Total Sentiment Polarity: 1.1\n",
            "\n",
            "Sentence: 'The weather is terrible today.'\n",
            "Total Sentiment Polarity: -1.0\n",
            "\n",
            "Sentence: 'Neutral sentences are neither positive nor negative.'\n",
            "Total Sentiment Polarity: -0.07272727272727272\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Write a code in python using ready function to input some tect  from user and identify each token in it\n",
        "\n",
        "# 2) How HMM can be used for tagging illustrate python code for probability , transition probability and emission"
      ],
      "metadata": {
        "id": "6xFqBS_1lS6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUnarS6Fo5Im",
        "outputId": "29dced60-af7b-412e-f3be-0c826750219a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKMR-UFpo5Tm",
        "outputId": "3bd15333-34ec-4154-d7c9-93a2f32c69bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('punkt')  # Download the necessary NLTK data\n",
        "\n",
        "# Input text from the user\n",
        "user_input = input(\"Enter a sentence: \")\n",
        "\n",
        "# Tokenize the input text\n",
        "tokens = word_tokenize(user_input)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Print the token and its corresponding POS tag\n",
        "for token, pos_tag in pos_tags:\n",
        "    print(f\"Token: {token}, POS Tag: {pos_tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK5w4e5Mo5bp",
        "outputId": "463d5376-1f08-413c-87d8-a6cc60a66657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: my roll number is 4163\n",
            "Token: my, POS Tag: PRP$\n",
            "Token: roll, POS Tag: NN\n",
            "Token: number, POS Tag: NN\n",
            "Token: is, POS Tag: VBZ\n",
            "Token: 4163, POS Tag: CD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the set of states (POS tags)\n",
        "states = ['Noun', 'Verb', 'Adjective', 'Adverb']\n",
        "\n",
        "# Define the transition matrix (example probabilities)\n",
        "# Each row represents the current state, and each column represents the next state\n",
        "transition_matrix = np.array([\n",
        "    [0.4, 0.3, 0.1, 0.2],  # Noun\n",
        "    [0.2, 0.4, 0.2, 0.2],  # Verb\n",
        "    [0.1, 0.2, 0.5, 0.2],  # Adjective\n",
        "    [0.3, 0.1, 0.2, 0.4]   # Adverb\n",
        "])\n",
        "\n",
        "# Define the emission matrix (example probabilities)\n",
        "# Rows represent states (POS tags), and columns represent words\n",
        "emission_matrix = np.array([\n",
        "    [0.1, 0.2, 0.3, 0.4],  # Noun\n",
        "    [0.3, 0.1, 0.2, 0.4],  # Verb\n",
        "    [0.2, 0.4, 0.2, 0.2],  # Adjective\n",
        "    [0.4, 0.2, 0.1, 0.3]   # Adverb\n",
        "])\n",
        "\n",
        "# Example input sentence (a sequence of words)\n",
        "sentence = [\"The\", \"quick\", \"brown\", \"fox\"]\n",
        "\n",
        "# Initialize a matrix to store the probabilities for each state at each position in the sentence\n",
        "# Each row represents a state, and each column represents a word position in the sentence\n",
        "probabilities = np.zeros((len(states), len(sentence)))\n",
        "\n",
        "\n",
        "# Initialize the probabilities for the first word in the sentence (emission probabilities)\n",
        "for i, state in enumerate(states):\n",
        "    probabilities[i, 0] = emission_matrix[i, sentence.index(sentence[0])]\n",
        "\n",
        "# Forward algorithm to calculate the probabilities for the remaining words\n",
        "for t in range(1, len(sentence)):\n",
        "    for j, current_state in enumerate(states):\n",
        "        probability_sum = 0\n",
        "        for i, previous_state in enumerate(states):\n",
        "            transition_prob = transition_matrix[i, j]\n",
        "            emission_prob = emission_matrix[j, sentence.index(sentence[t])]\n",
        "            probability_sum += probabilities[i, t - 1] * transition_prob * emission_prob\n",
        "        probabilities[j, t] = probability_sum\n",
        "\n",
        "# Print the final probabilities for each state at each position\n",
        "for i, state in enumerate(states):\n",
        "    print(f\"Probabilities for {state}: {probabilities[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXRHZ1Yao5gb",
        "outputId": "2c3e7153-c7ea-4e8b-e49c-780cc353329e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities for Noun: [0.1     0.048   0.01518 0.00446]\n",
            "Probabilities for Verb: [0.3      0.023    0.00984  0.004752]\n",
            "Probabilities for Adjective: [0.2       0.1       0.01412   0.0023356]\n",
            "Probabilities for Adverb: [0.4       0.056     0.00566   0.0030276]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PiIloVU6o5kT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}